{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12192642,"sourceType":"datasetVersion","datasetId":7679959}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.applications import EfficientNetV2B0\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras import layers\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = image_dataset_from_directory(\n    '/kaggle/input/datasets-tumer/brain_tumor_dataset',\n    labels='inferred',\n    label_mode='binary',\n    validation_split=0.2,\n    subset='training',\n    seed=123,\n    image_size=(224, 224),\n    batch_size=32\n)\n\nval_ds = image_dataset_from_directory(\n    '/kaggle/input/datasets-tumer/brain_tumor_dataset',\n    labels='inferred',\n    label_mode='binary',\n    validation_split=0.2,\n    subset='validation',\n    seed=123,\n    image_size=(224, 224),\n    batch_size=32\n)\n\n# Prefetch for performance\nAUTOTUNE = tf.data.AUTOTUNE\ntrain_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data augmentation\ndata_augmentation = tf.keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomZoom(0.1),\n    layers.RandomRotation(0.1),\n])\n\n# Load EfficientNet\nbase_model = EfficientNetV2B0(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\nbase_model.trainable = True  # Enable fine-tuning!\n\n# Build final model\nmodel = Sequential([\n    data_augmentation,\n    base_model,\n    GlobalAveragePooling2D(),\n    Dense(128, activation='relu'),\n    Dropout(0.3),\n    Dense(1, activation='sigmoid')  # binary classification\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n\ncheckpoint = ModelCheckpoint('best_model.h5',\n                             monitor='val_accuracy',\n                             save_best_only=True,\n                             verbose=1)\n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=25,  # Increase if needed\n    callbacks=[early_stop, checkpoint]\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loss, train_acc = model.evaluate(train_ds, verbose=0)\nval_loss, val_acc = model.evaluate(val_ds, verbose=0)\n\nprint(f\"✅ Recalculated Train Accuracy: {train_acc * 100:.2f}%\")\nprint(f\"✅ Recalculated Test Accuracy: {val_acc * 100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimg_path = '/kaggle/input/datasets-tumer/yes/Y108.jpg'\n\nimg = image.load_img(img_path, target_size=(224, 224))\nimg_array = image.img_to_array(img) / 255.0\nimg_array = np.expand_dims(img_array, axis=0)\n\nplt.imshow(img)\nplt.axis(False)\nplt.title(\"Test Image\")\nplt.show()\n\npred = model.predict(img_array)[0][0]\nprint(\"Prediction probability:\", pred)\n\nprint(\"✅ Tumor Detected\" if pred > 0.5 else \"❌ No Tumor\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.utils import class_weight\nimport numpy as np\n\n# Extract labels from dataset\nall_labels = []\nfor _, labels in train_ds.unbatch():\n    all_labels.append(int(labels.numpy()))\n\n# Calculate class weights\nclass_weights = class_weight.compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(all_labels),\n    y=all_labels\n)\n\n# Convert to dict\nclass_weights = {i: weight for i, weight in enumerate(class_weights)}\nprint(\"Class weights:\", class_weights)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=25,\n    callbacks=[early_stop, checkpoint],\n    class_weight=class_weights  # << ADD THIS!\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loss, train_acc = model.evaluate(train_ds, verbose=0)\nval_loss, val_acc = model.evaluate(val_ds, verbose=0)\n\nprint(f\"✅ Recalculated Train Accuracy: {train_acc * 100:.2f}%\")\nprint(f\"✅ Recalculated Test Accuracy: {val_acc * 100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = image_dataset_from_directory(\n    '/kaggle/input/datasets-tumer/brain_tumor_dataset',\n    labels='inferred',\n    label_mode='binary',\n    validation_split=0.2,\n    subset='training',\n    seed=123,\n    image_size=(256, 256),\n    batch_size=32\n)\n\nval_ds = image_dataset_from_directory(\n    '/kaggle/input/datasets-tumer/brain_tumor_dataset',\n    labels='inferred',\n    label_mode='binary',\n    validation_split=0.2,\n    subset='validation',\n    seed=123,\n    image_size=(256, 256),\n    batch_size=32\n)\n\n# Prefetch for performance\nAUTOTUNE = tf.data.AUTOTUNE\ntrain_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.regularizers import l2\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\n\n# ✅ Define custom binary focal loss\ndef binary_focal_loss(gamma=2.0, alpha=0.25):\n    def focal_loss_fixed(y_true, y_pred):\n        epsilon = K.epsilon()\n        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n        p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n        alpha_t = tf.where(K.equal(y_true, 1), alpha, 1 - alpha)\n        loss = -alpha_t * K.pow(1 - p_t, gamma) * K.log(p_t)\n        return K.mean(loss)\n    return focal_loss_fixed\n\n# ✅ Load MobileNetV2\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\nbase_model.trainable = True  # Fine-tune all layers\n\n# ✅ Data augmentation\ndata_augmentation = tf.keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomZoom(0.1),\n    layers.RandomRotation(0.1),\n])\n\n# ✅ Define the model\nmodel = Sequential([\n    data_augmentation,\n    base_model,\n    GlobalAveragePooling2D(),\n    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')  # Binary classification\n])\n\n# ✅ Normalize pixel values\nnormalization_layer = tf.keras.layers.Rescaling(1./255)\ntrain_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\nval_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n\n# ✅ Compile the model using custom focal loss\nmodel.compile(\n    optimizer='adam',\n    loss=binary_focal_loss(gamma=2.0, alpha=0.25),\n    metrics=['accuracy']\n)\n\n# ✅ Show model architecture\nmodel.summary()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\n# Check GPU\nprint(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\nprint(\"TensorFlow is using GPU:\", tf.test.is_gpu_available(cuda_only=True))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n\ncheckpoint = ModelCheckpoint('best_model.h5',\n                             monitor='val_accuracy',\n                             save_best_only=True,\n                             verbose=1)\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=25,  # Increase if needed\n    callbacks=[early_stop, checkpoint]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Training Accuracy:\", history.history['accuracy'][-1])\nprint(\"Validation Accuracy:\", history.history['val_accuracy'][-1])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nno_count = len(os.listdir('/kaggle/input/datasets-tumer/no'))\nyes_count = len(os.listdir('/kaggle/input/datasets-tumer/yes'))\n\nprint(\"No Tumor:\", no_count)\nprint(\"Yes Tumor:\", yes_count)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Main MOdel**","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# =======================\n# 1. Load Dataset\n# =======================\nDATASET_PATH = \"/kaggle/input/datasets-tumer/brain_tumor_dataset\"\nBATCH_SIZE = 32\nIMG_SIZE = (224, 224)\n\ntrain_ds = image_dataset_from_directory(\n    DATASET_PATH,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=123,\n    label_mode='binary',\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE\n)\n\nval_ds = image_dataset_from_directory(\n    DATASET_PATH,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=123,\n    label_mode='binary',\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE\n)\n\n# =======================\n# 2. Data Augmentation & Normalization\n# =======================\ndata_augmentation = tf.keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomZoom(0.2),\n    layers.RandomRotation(0.2),\n    layers.RandomContrast(0.2),\n    layers.RandomTranslation(0.1, 0.1),\n])\n\nnormalization_layer = tf.keras.layers.Rescaling(1./255)\nAUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)).cache().shuffle(1000).prefetch(AUTOTUNE)\nval_ds = val_ds.map(lambda x, y: (normalization_layer(x), y)).cache().prefetch(AUTOTUNE)\n\n# =======================\n# 3. Compute Class Weights\n# =======================\nlabels = []\nfor _, y in train_ds.unbatch():\n    labels.append(int(y.numpy().item()))\n\nclass_weights = class_weight.compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(labels),\n    y=labels\n)\nclass_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n\n# =======================\n# 4. Build Model\n# =======================\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nbase_model.trainable = False\n\nmodel = Sequential([\n    data_augmentation,\n    base_model,\n    GlobalAveragePooling2D(),\n    Dense(256, activation='relu', kernel_regularizer=l2(1e-4)),\n    Dropout(0.3),\n    Dense(1, activation='sigmoid')  # Binary classification\n])\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n    loss='binary_crossentropy',\n    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n)\n\n# =======================\n# 5. Warm-up Training\n# =======================\nprint(\"\\n🔧 Warm-up training...\")\nmodel.fit(train_ds, validation_data=val_ds, epochs=5, class_weight=class_weights_dict)\n\n# =======================\n# 6. Fine-tuning\n# =======================\nfor layer in base_model.layers[:-50]:\n    layer.trainable = False\nfor layer in base_model.layers[-50:]:\n    layer.trainable = True\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n    loss='binary_crossentropy',\n    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n)\n\ncallbacks = [\n    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n    ModelCheckpoint('/kaggle/working/best_model_1.h5', save_best_only=True, monitor='val_accuracy', verbose=1)\n]\n\nprint(\"\\n🎯 Fine-tuning training...\")\nhistory = model.fit(train_ds, validation_data=val_ds, epochs=30, callbacks=callbacks, class_weight=class_weights_dict)\n\n# =======================\n# 7. Load Best Model\n# =======================\nbest_model = load_model('/kaggle/working/best_model_1.h5')\n\n# =======================\n# 8. Evaluation\n# =======================\nresults = best_model.evaluate(val_ds)\nprint(\"\\n✅ Loaded Best Model Evaluation:\")\nfor metric, value in zip(best_model.metrics_names, results):\n    print(f\"{metric}: {value:.4f}\")\n\nbest_val_acc = max(history.history['val_accuracy'])\nprint(f\"\\n🔥 Best Validation Accuracy Achieved: {best_val_acc:.4f}\")\n\n# =======================\n# 9. Classification Report\n# =======================\ny_true, y_pred = [], []\nfor images, labels in val_ds:\n    preds = best_model.predict(images).flatten()\n    y_true.extend(labels.numpy())\n    y_pred.extend((preds > 0.5).astype(int))\n\nprint(\"\\n🧾 Classification Report:\")\nprint(classification_report(y_true, y_pred, target_names=['No Tumor', 'Tumor']))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nprint(os.listdir())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = tf.keras.models.load_model(\"/kaggle/working/best_model_1.h5\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_model = model.get_layer('mobilenetv2_1.00_224')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for layer in reversed(base_model.layers):\n    if 'conv' in layer.name and 'conv_pw' not in layer.name:\n        print(\"Last conv layer:\", layer.name)\n        last_conv_layer_name = layer.name\n        break\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datetime import datetime\nimport os\n\n# Create a folder to store multiple versions\nos.makedirs(\"/kaggle/working/models\", exist_ok=True)\n\n# Generate a unique filename using date + time\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nversioned_model_path = f\"/kaggle/working/models/best_model_{timestamp}.h5\"\n\n# Save the model\nmodel.save(versioned_model_path)\n\nprint(f\"✅ Model saved as {versioned_model_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Sub Model**","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# =======================\n# 1. Load Dataset\n# =======================\nDATASET_PATH = \"/kaggle/input/datasets-tumer/brain_tumor_dataset\"\nBATCH_SIZE = 32\nIMG_SIZE = (224, 224)\n\ntrain_ds = image_dataset_from_directory(\n    DATASET_PATH,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=123,\n    label_mode='binary',  # This is correct for multi-class\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE\n)\n\nval_ds = image_dataset_from_directory(\n    DATASET_PATH,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=123,\n    label_mode='binary',\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE\n)\n\n\n# =======================\n# 2. Data Augmentation & Normalization\n# =======================\ndata_augmentation = tf.keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomZoom(0.2),\n    layers.RandomRotation(0.2),\n    layers.RandomContrast(0.2),\n    layers.RandomTranslation(0.1, 0.1),\n])\n\nnormalization_layer = tf.keras.layers.Rescaling(1./255)\nAUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)).cache().shuffle(1000).prefetch(AUTOTUNE)\nval_ds = val_ds.map(lambda x, y: (normalization_layer(x), y)).cache().prefetch(AUTOTUNE)\n\n# =======================\n# 3. Compute Class Weights\n# =======================\nlabels = []\nfor _, y in train_ds.unbatch():\n    labels.append(int(y.numpy().item()))\n\n\nclass_weights = class_weight.compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(labels),\n    y=labels\n)\nclass_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n\n# =======================\n# 4. Build Model\n# =======================\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nbase_model.trainable = False\n\nmodel = Sequential([\n    data_augmentation,\n    base_model,\n    GlobalAveragePooling2D(),\n    Dense(256, activation='relu', kernel_regularizer=l2(1e-4)),\n    Dropout(0.3),\n    Dense(1, activation='sigmoid')  # <-- Multiclass output\n])\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n    loss='binary_crossentropy',\n    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n)\n\n# =======================\n# 5. Warm-up Training\n# =======================\nprint(\"\\n🔧 Warm-up training...\")\nmodel.fit(train_ds, validation_data=val_ds, epochs=5, class_weight=class_weights_dict)\n\n# =======================\n# 6. Fine-tuning\n# =======================\nfor layer in base_model.layers[:-50]:\n    layer.trainable = False\nfor layer in base_model.layers[-50:]:\n    layer.trainable = True\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n    loss='binary_crossentropy',\n    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n)\n\ncallbacks = [\n    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n    ModelCheckpoint('/kaggle/working/best_model.h5', save_best_only=True, monitor='val_accuracy', verbose=1)\n]\n\nprint(\"\\n🎯 Fine-tuning training...\")\nhistory = model.fit(train_ds, validation_data=val_ds, epochs=30, callbacks=callbacks, class_weight=class_weights_dict)\n\n\nfrom tensorflow.keras.models import load_model\n\nbest_model = load_model('/kaggle/working/best_model_1.h5')\n\n# =======================\n\n# =======================\n# 9. Evaluation\n# =======================\n\n# Evaluate or use\nresults = best_model.evaluate(val_ds)\nprint(\"\\n✅ Loaded Best Model Evaluation:\")\nfor metric, value in zip(best_model.metrics_names, results):\n    print(f\"{metric}: {value:.4f}\")\n\n\nbest_val_acc = max(history.history['val_accuracy'])\nprint(f\"🔥 Best Validation Accuracy Achieved: {best_val_acc:.4f}\")\n\n# =======================\n# 8. Classification Report\n# =======================\ny_true, y_pred = [], []\nfor images, labels in val_ds:\n    preds = model.predict(images).flatten()  # sigmoid outputs\n    y_true.extend(labels.numpy())\n    y_pred.extend((preds > 0.5).astype(int))\n\nprint(\"\\n🧾 Classification Report:\")\nprint(classification_report(y_true, y_pred, target_names=['No Tumor', 'Tumor']))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_path = '/kaggle/input/datasets-tumer/no/13 no.jpg'  # Or a \"no\" image\nimg = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Add batch dim\nimg_array = normalization_layer(img_array)\n\npred = best_model.predict(img_array)[0][0]\nprint(\"\\n🔍 Prediction Probability:\", pred)\nprint(\"✅ Tumor Detected\" if pred > 0.4 else \"❌ No Tumor\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Model\nfrom PIL import Image\n\ndef get_gradcam_heatmap(img_array, model, last_conv_layer_name):\n    grad_model = Model(\n        inputs=[model.inputs],\n        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n    )\n    \n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        class_idx = tf.argmax(predictions[0])\n        loss = predictions[:, class_idx]\n\n    grads = tape.gradient(loss, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    conv_outputs = conv_outputs[0]\n\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\ndef overlay_heatmap(heatmap, image, alpha=0.4):\n    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n    heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n    output = cv2.addWeighted(image, 1 - alpha, heatmap_colored, alpha, 0)\n    return output\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nprint(\"Working dir contents:\", os.listdir('/kaggle/working'))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nprint(os.listdir('/kaggle/working'))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 7: Predict New Image (Not from Dataset)\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\nimport matplotlib.pyplot as plt\n\ndef predict_image(img_path):\n    img = image.load_img(img_path, target_size=(256, 256))\n    img_array = image.img_to_array(img)\n    img_array = img_array / 255.0  # manual normalization\n    img_array = np.expand_dims(img_array, axis=0)\n\n    # Predict\n    prediction = model.predict(img_array)[0][0]\n    label = \"✅ Tumor Detected\" if prediction > 0.40 else \"❌ No Tumor\"\n   \n    # Show result\n    plt.imshow(img)\n    plt.axis('off')\n    plt.title(f\"Prediction: {label} ({prediction:.2f})\")\n    plt.show()\n    \n\n\n# Example usage\npredict_image('/kaggle/input/datasets-tumer/yes/Y13.jpg')\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_weights = {\n    0: total/ (2 * no_count),\n    1: total/ (2 * yes_count)\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for images, labels in val_ds.take(1):\n    preds = model.predict(images)\n    for i in range(len(preds)):\n        true = int(labels[i].numpy())\n        pred = 1 if preds[i][0] > 0.5 else 0\n        if true != pred:\n            plt.imshow(images[i].numpy().astype(\"uint8\"))\n            plt.title(f\"❌ Wrong | True: {true} | Pred: {pred} ({preds[i][0]:.2f})\")\n            plt.axis(False)\n            plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.utils import class_weight\nimport numpy as np\n\n# Get class weights\nall_labels = []\nfor _, labels in train_ds.unbatch():\n    all_labels.append(int(labels.numpy()))\n\nclass_weights = class_weight.compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(all_labels),\n    y=all_labels\n)\nclass_weights = {i: weight for i, weight in enumerate(class_weights)}\nprint(\"Class weights:\", class_weights)\n\n# Train\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=25,\n    callbacks=[early_stop, checkpoint],\n    class_weight=class_weights\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = model.predict(img_array)[0][0]\nprint(\"Prediction probability:\", pred)\nprint(\"✅ Tumor Detected\" if pred > 0.5 else \"❌ No Tumor\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Training Accuracy:\", history.history['accuracy'][-1])\nprint(\"Validation Accuracy:\", history.history['val_accuracy'][-1])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Val Accuracy')\nplt.title(\"Accuracy over Epochs\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}